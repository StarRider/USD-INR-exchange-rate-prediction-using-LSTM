{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Configuration\n",
        "\n",
        "Model file (lstm_model_month_deep_15.pkl) is located in Google Drive."
      ],
      "metadata": {
        "id": "mlONufss5z4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# if True then model will not be trained and predictions won't be done.\n",
        "monitor_pred = True\n",
        "\n",
        "root = \"/content/drive/MyDrive/\"\n",
        "\n",
        "# model name\n",
        "MODEL = {\n",
        "    \"Deep_30_15\": {\"path\": root + \"lstm_model_month_deep_15.pkl\",\n",
        "                   \"period\": 30,\n",
        "                   \"n_steps\": 30,\n",
        "                   \"n_ahead\": 15,\n",
        "                   \"update\": True\n",
        "                   }\n",
        "}"
      ],
      "metadata": {
        "id": "4g-e6WZg5wyk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data preprocessing modules"
      ],
      "metadata": {
        "id": "7gfYIqmN59si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "\n",
        "def get_usd_inr_history(days):\n",
        "    \"\"\"\n",
        "    Fetches data from yahoo finance.\n",
        "    :param days: Integer that fetches history for past n number of days.\n",
        "    :return: raw exchange rate data as dataframe\n",
        "    \"\"\"\n",
        "    yf_inr = yf.Ticker(\"INR=X\")\n",
        "    data = yf_inr.history(\"{}d\".format(days))\n",
        "    return data\n",
        "\n",
        "\n",
        "def preprocess(df):\n",
        "    \"\"\"\n",
        "    This function does preprocessing of raw data.\n",
        "    :param df: The raw dataframe df fetched directly from yahoo finance.\n",
        "    :return: A preprocessed dataframe.\n",
        "    \"\"\"\n",
        "    # reset index (Converting the date index to column)\n",
        "    df = df.reset_index()\n",
        "\n",
        "    # Convert 'date' column to datetime format\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # Create a new column with the month number\n",
        "    df['Month'] = df['Date'].dt.month\n",
        "\n",
        "    # Drop the date and other unwanted columns column\n",
        "    df = df.drop(columns=['Date', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits'])\n",
        "\n",
        "    # Replace null with the previous value\n",
        "    df = df.fillna(method='ffill')\n",
        "\n",
        "    # round to 2 decimal places\n",
        "    df_round = df.round(2)\n",
        "\n",
        "    return df_round\n",
        "\n",
        "\n",
        "def post_processing(df):\n",
        "    \"\"\"\n",
        "    This function expects that programmer has use preprocess on df\n",
        "    otherwise it will raise an error.\n",
        "    :param df: preprocessed dataframe using function preprocess()\n",
        "    :return: return post processed df with seasonally adjusted data and month\n",
        "    \"\"\"\n",
        "    required_cols = ['Open', 'Month']\n",
        "\n",
        "    if len(df.columns) != 2:\n",
        "        raise Exception(\"Invalid dataframe. First pre-process using 'preprocess' function.\")\n",
        "\n",
        "    for col in required_cols:\n",
        "        if col not in df.columns:\n",
        "            raise Exception(\"Invalid dataframe. First pre-process using 'preprocess' function.\")\n",
        "\n",
        "    # 30 day differencing\n",
        "    period = 30\n",
        "\n",
        "    # creating a new column Adj with seasonal adjustments\n",
        "    df[\"Adj\"] = df[\"Open\"].diff(period)\n",
        "\n",
        "    # drop the \"Open\" columns\n",
        "    df = df.drop(\"Open\", axis=1)\n",
        "\n",
        "    # omitting the first 30 nulls in Adj column\n",
        "    df = df[30:]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def prepare_data(data, n_steps, n_ahead=1):\n",
        "    \"\"\"\n",
        "    This function prepares post processed data for feeding it into the LSTM network.\n",
        "    :param data: Post processed dataframe.\n",
        "    :param n_steps: Number of timesteps used to training\n",
        "    :param n_ahead: Number of timesteps to be predicted\n",
        "    :return: Input X and Label y for the LSTM network\n",
        "    \"\"\"\n",
        "    X = np.array([data[i:i + n_steps] for i in range(len(data) - n_steps + 1)])[:-n_ahead]\n",
        "    y = np.array([data[n_steps:, 1][i:i + n_ahead] for i in range(len(data[n_steps:]) - n_ahead + 1)])\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def create_test_input(df, n_steps, n_ahead):\n",
        "    \"\"\"\n",
        "    This function creates an input for LSTM using the last 30 days df data\n",
        "    so that LSTM can predict rates for next 15 days.\n",
        "    :param df: Post processed dataframe.\n",
        "    :return: Test input numpy array.\n",
        "    \"\"\"\n",
        "    # taking the last period as test for which no label exists\n",
        "    X = np.array([df[i:i + n_steps] for i in range(len(df) - n_steps + 1)])[-n_ahead:][-1]\n",
        "\n",
        "    # reshape it because the result X_test is 2D we need a 3D input for LSTM model\n",
        "    X = X.reshape(1, X.shape[0], X.shape[1])\n",
        "\n",
        "    return X\n",
        "\n",
        "\n",
        "def create_train_test(df, fraction, n_steps, n_ahead):\n",
        "    \"\"\"\n",
        "    This function create training and testing data for training a new model.\n",
        "    :param df: Post processed data.\n",
        "    :param fraction: Fraction of df assigned for training.\n",
        "    :param n_steps: Number of timesteps used to training\n",
        "    :param n_ahead: Number of timesteps to be predicted\n",
        "    :return: X_train, y_train, X_test and y_test\n",
        "    \"\"\"\n",
        "    split_idx = int(fraction * df.shape[0])\n",
        "    train = np.array(df[:split_idx])\n",
        "    test = np.array(df[split_idx:])\n",
        "\n",
        "    # Split data into input and output samples\n",
        "    X_train, y_train = prepare_data(train, n_steps, n_ahead)\n",
        "    X_test, y_test = prepare_data(test, n_steps, n_ahead)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\n",
        "def retrieve(history, yhat, n_steps, n_ahead, period, split_idx=None, y_test=None):\n",
        "    \"\"\"\n",
        "    This function retrieves the original values predicted that is reconstructed from the\n",
        "    seasonally adjusted predictions.\n",
        "    :param history: The complete \"Open\" price.\n",
        "    :param yhat: Predictions from the model.\n",
        "    :param n_steps: Number of timesteps used to training.\n",
        "    :param n_ahead: Number of timesteps to be predicted.\n",
        "    :param period: Seasonal differencing period.\n",
        "    :param split_idx: index at which the fraction of training dataset ends.\n",
        "    :param y_test: the actual values that is expected to be predicted.\n",
        "    :return: Original INR value of USD.\n",
        "    \"\"\"\n",
        "    if split_idx:\n",
        "        if y_test:\n",
        "            lag_arr = history[:-period][split_idx:][n_steps:]\n",
        "            lag_matrix = np.array([lag_arr[i:i + n_ahead] for i in range(len(lag_arr) - n_ahead + 1)])\n",
        "            y_test2 = y_test + lag_matrix\n",
        "        else:\n",
        "            raise Exception(\"y_test not given\")\n",
        "    else:\n",
        "        lag_arr = history[:-period][-n_steps:]\n",
        "        lag_matrix = np.array([lag_arr[i:i + n_ahead] for i in range(len(lag_arr) - n_ahead + 1)])[-1]\n",
        "        # Just passing None to y_test2\n",
        "        y_test2 = y_test\n",
        "\n",
        "    yhat2 = yhat + lag_matrix\n",
        "\n",
        "    return yhat2, y_test2\n",
        "\n",
        "def next_working_day(date_str, date_format):\n",
        "    # Convert the date string to a datetime object\n",
        "    date_obj = datetime.strptime(date_str, date_format).date()\n",
        "\n",
        "    # Define a function to check if a date is a business day\n",
        "    def is_business_day(date):\n",
        "        return date.weekday() < 5  # Monday to Friday are business days (0-4)\n",
        "\n",
        "    # Add days until a business day is found\n",
        "    next_day = date_obj + timedelta(days=1)\n",
        "\n",
        "    while not is_business_day(next_day):\n",
        "        print(next_day)\n",
        "        next_day += timedelta(days=1)\n",
        "\n",
        "    # Convert the next working day back to the string format\n",
        "    return next_day.strftime(date_format)"
      ],
      "metadata": {
        "id": "iaBJfFp_n-qi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model training\n",
        "Along with training model, the weights and corresponding history, 15-day predictions are saved in the Google drive."
      ],
      "metadata": {
        "id": "8kc7Kjda6GyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "\n",
        "if not monitor_pred:\n",
        "  # fetching configurations\n",
        "  print(\"Fetching configurations...\")\n",
        "  model_name = \"Deep_30_15\"\n",
        "  n_steps = MODEL[model_name][\"n_steps\"]\n",
        "  n_ahead = MODEL[model_name][\"n_ahead\"]\n",
        "  period = MODEL[model_name][\"period\"]\n",
        "  model_path = MODEL[model_name][\"path\"]\n",
        "\n",
        "  # calculating past days\n",
        "  days = round(n_ahead/2)*n_steps + n_ahead\n",
        "\n",
        "  # getting historical exchange rates from yahoo finance\n",
        "  print(\"Loading {} days historical data from yahoo finance...\".format(days))\n",
        "  data = get_usd_inr_history(days)\n",
        "\n",
        "  # save the loaded data to google drive\n",
        "  print(\"Saving loaded data to google drive as history.csv...\")\n",
        "  data.to_csv(root + \"history.csv\")\n",
        "\n",
        "  # processing raw data\n",
        "  print(\"Processing the raw data...\")\n",
        "  data_processed = preprocess(data)\n",
        "  data_pst_processed = np.array(post_processing(data_processed))\n",
        "\n",
        "  # prepare data for feeding to LSTM network\n",
        "  print(\"Modifying data for feeding into LSTM model...\")\n",
        "  X, y = prepare_data(data=data_pst_processed, n_steps=n_steps, n_ahead=n_ahead)\n",
        "\n",
        "  # create test input (Note: it has no label to compare, we just need an input to feed to LSTM)\n",
        "  print(\"Creating test input for LSTM model...\")\n",
        "  X_test = create_test_input(df=data_pst_processed, n_steps=n_steps, n_ahead=n_ahead)\n",
        "\n",
        "  # load the model\n",
        "  if os.path.isfile(model_path):\n",
        "      print(\"Loading exiting model: {}\".format(model_path))\n",
        "\n",
        "      with open(model_path, \"rb\") as file:\n",
        "          model = pickle.load(file)\n",
        "\n",
        "      # if model requires an update then train it on latest data\n",
        "      if MODEL[model_name][\"update\"]:\n",
        "          print(\"Updating model parameters...\")\n",
        "          model.fit(X, y, epochs=50, verbose=1)\n",
        "\n",
        "          print(\"Save the updated model...\")\n",
        "          with open(model_path, \"wb\") as file:\n",
        "            pickle.dump(model, file)\n",
        "\n",
        "\n",
        "      # predict seasonally adjusted values\n",
        "      print(\"Making predictions...\")\n",
        "      yhat = model.predict(X_test, verbose=0)\n",
        "\n",
        "      # retrieve the values\n",
        "      print(\"Reversing seasonal adjustments...\")\n",
        "      yhat2, _ = retrieve(history=data[\"Open\"], yhat=yhat,\n",
        "                      n_steps=n_steps, n_ahead=n_ahead, period=period,\n",
        "                      split_idx=None, y_test=None)\n",
        "\n",
        "      # creates future dates (We omit saturdays and sundays. Only need business days.)\n",
        "      print(\"Generating forecast dates...\")\n",
        "      forecast_dates = [np.datetime64('today') + i for i in range(1, n_ahead+1) if\n",
        "                        np.is_busday(np.datetime64('today') + i)]\n",
        "\n",
        "      while len(forecast_dates) < n_ahead:\n",
        "          if np.is_busday(forecast_dates[-1] + 1):\n",
        "              forecast_dates.append(forecast_dates[-1] + 1)\n",
        "          else:\n",
        "              # this means that the next day is Saturday\n",
        "              forecast_dates.append(forecast_dates[-1] + 3)\n",
        "\n",
        "      forecast_dates = np.array(forecast_dates)\n",
        "\n",
        "      # Zip these dates and yhat2 (retrieved values) together\n",
        "      print(\"Zipping forecasts and dates...\")\n",
        "      yhat2 = yhat2.flatten()\n",
        "      forecast_dates = forecast_dates.flatten()\n",
        "      pred = {\"Date\": forecast_dates,\n",
        "              \"Open\": yhat2}\n",
        "\n",
        "      print(\"Creating a dataframe and saving it...\")\n",
        "      final_df = pd.DataFrame(pred)\n",
        "\n",
        "      # save the df\n",
        "      final_df.to_csv(root + \"prediction.csv\")\n",
        "\n",
        "      print(\"Program finished successfully!\")\n",
        "else:\n",
        "  print(\"Monitoring past prediction mode...\")\n",
        "  # get the history\n",
        "  history_path = root + \"/\" + \"history.csv\"\n",
        "  hist = pd.read_csv(history_path)\n",
        "  latest_date_str = hist[\"Date\"].iloc[-1].split()[0]\n",
        "  latest_date_str_format = '%Y-%m-%d'\n",
        "  latest_day = datetime.strptime(latest_date_str, latest_date_str_format)\n",
        "\n",
        "  # get the set of data from the last day till today\n",
        "  yf_inr = yf.Ticker(\"INR=X\")\n",
        "  new_data = yf_inr.history(start=next_working_day(latest_date_str, latest_date_str_format))\n",
        "\n",
        "  new_data.head()\n",
        "\n",
        "  # keep only Date and Open columns\n",
        "  new_data = new_data.drop(columns=[\"High\", \"Low\", \"Close\", \"Volume\", \"Dividends\", \"Stock Splits\"])\n",
        "\n",
        "  # save the data in Google drive\n",
        "  new_data.to_csv(root + \"/compare.csv\")\n",
        "\n",
        "  print(\"Latest Open prices saved to Google Drive. (file name is compare.csv)\")\n",
        "  print(\"Program finished successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LkUwaV-n_8e",
        "outputId": "84474975-e8f1-474d-8d20-77acffcc7607"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monitoring past prediction mode...\n",
            "Latest Open prices saved to Google Drive. (file name is compare.csv)\n",
            "Program finished successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tu-g8Q6d7yPy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}